import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase
import av
import cv2
import mediapipe as mp
import time
from datetime import datetime
from zoneinfo import ZoneInfo

# ì„¤ì •
st.set_page_config(page_title="ë‚™ìƒ ê°ì§€ ì‹œìŠ¤í…œ", layout="wide")
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# ì‹œê°„ í•¨ìˆ˜
def now_kst():
    return datetime.now(ZoneInfo("Asia/Seoul")).strftime("%Y-%m-%d %H:%M:%S")

# ğŸ§  ê´€ì ˆ ì¶”ì¶œ í´ë˜ìŠ¤ (ì›¹ìº ìš©)
class PoseVideoProcessor(VideoProcessorBase):
    def __init__(self):
        self.pose = mp_pose.Pose()
        self.landmark_data = {}

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        image = frame.to_ndarray(format="bgr24")
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.pose.process(image_rgb)

        if results.pose_landmarks:
            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
            def extract(p): return {"x": p.x, "y": p.y, "z": p.z, "visibility": p.visibility}
            lm = results.pose_landmarks.landmark
            self.landmark_data = {
                "timestamp": now_kst(),
                "left_shoulder": extract(lm[mp_pose.PoseLandmark.LEFT_SHOULDER]),
                "right_shoulder": extract(lm[mp_pose.PoseLandmark.RIGHT_SHOULDER]),
                "left_knee": extract(lm[mp_pose.PoseLandmark.LEFT_KNEE]),
                "right_knee": extract(lm[mp_pose.PoseLandmark.RIGHT_KNEE])
            }

        return av.VideoFrame.from_ndarray(image, format="bgr24")

# ğŸ§© ì„ íƒ ë©”ë‰´
mode = st.radio("ë¶„ì„ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ğŸ“· ì›¹ìº  ìŠ¤íŠ¸ë¦¬ë°", "ğŸï¸ MP4 ì˜ìƒ ì—…ë¡œë“œ"])

# ğŸ“· ì›¹ìº  ëª¨ë“œ
if mode == "ğŸ“· ì›¹ìº  ìŠ¤íŠ¸ë¦¬ë°":
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ì‹¤ì‹œê°„ ì˜ìƒ")
        webrtc_ctx = webrtc_streamer(
            key="webcam",
            video_processor_factory=PoseVideoProcessor,
            media_stream_constraints={"video": True, "audio": False},
            async_processing=True,
        )

    with col2:
        st.subheader("ê´€ì ˆ ì •ë³´")
        landmark_box = st.empty()

        if webrtc_ctx.video_processor:
            processor = webrtc_ctx.video_processor
            last_print_time = 0
            while True:
                current_time = time.time()
                data = processor.landmark_data

                if data and current_time - last_print_time >= 1:
                    def fmt(j): return {
                        "X": f"{j['x']:.2f}", "Y": f"{j['y']:.2f}",
                        "Z": f"{j['z']:.2f}", "ì‹ ë¢°ë„": f"{j['visibility']:.2f}",
                        "ì í•©": "ì í•©" if j['visibility'] > 0.7 else "ë¶€ì í•©"
                    }
                    formatted = {
                        "ì‹œê°„": data["timestamp"],
                        "ì™¼ìª½ ì–´ê¹¨": fmt(data["left_shoulder"]),
                        "ì˜¤ë¥¸ìª½ ì–´ê¹¨": fmt(data["right_shoulder"]),
                        "ì™¼ìª½ ë¬´ë¦": fmt(data["left_knee"]),
                        "ì˜¤ë¥¸ìª½ ë¬´ë¦": fmt(data["right_knee"]),
                    }
                    md = f"**ğŸ•’ {formatted['ì‹œê°„']}**\n\n| êµ¬ë¶„ | X | Y | Z | ì‹ ë¢°ë„ | ì í•© |\n|:--:|:--:|:--:|:--:|:--:|:--:|\n"
                    for name, joint in formatted.items():
                        if name != "ì‹œê°„":
                            md += f"| {name} | {joint['X']} | {joint['Y']} | {joint['Z']} | {joint['ì‹ ë¢°ë„']} | {joint['ì í•©']} |\n"
                    landmark_box.markdown(md)
                    last_print_time = current_time

                time.sleep(0.1)

# ğŸï¸ ì˜ìƒ ì—…ë¡œë“œ ëª¨ë“œ
else:
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("MP4 ì˜ìƒ ì—…ë¡œë“œ")
        video_file = st.file_uploader("MP4 íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["mp4"])
        if video_file:
            file_path = f"./mov/uploaded_{video_file.name}"
            with open(file_path, "wb") as f:
                f.write(video_file.read())

            cap = cv2.VideoCapture(file_path)
            frame_placeholder = st.empty()
            pose = mp_pose.Pose()
            stop_button = st.button("â¹ ì˜ìƒ ì²˜ë¦¬ ì¤‘ì§€")
            last_print_time = 0

    with col2:
        if video_file:
            landmark_output = st.empty()
            while cap.isOpened() and not stop_button:
                ret, frame = cap.read()
                if not ret:
                    st.success("ì˜ìƒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    break

                image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = pose.process(image_rgb)

                if results.pose_landmarks:
                    mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                    def extract(p): return {"x": p.x, "y": p.y, "z": p.z, "visibility": p.visibility}
                    lm = results.pose_landmarks.landmark
                    data = {
                        "timestamp": now_kst(),
                        "left_shoulder": extract(lm[mp_pose.PoseLandmark.LEFT_SHOULDER]),
                        "right_shoulder": extract(lm[mp_pose.PoseLandmark.RIGHT_SHOULDER]),
                        "left_knee": extract(lm[mp_pose.PoseLandmark.LEFT_KNEE]),
                        "right_knee": extract(lm[mp_pose.PoseLandmark.RIGHT_KNEE])
                    }

                    current_time = time.time()
                    if current_time - last_print_time >= 1:
                        def fmt(j): return {
                            "X": f"{j['x']:.2f}", "Y": f"{j['y']:.2f}",
                            "Z": f"{j['z']:.2f}", "ì‹ ë¢°ë„": f"{j['visibility']:.2f}",
                            "ì í•©": "ì í•©" if j['visibility'] > 0.7 else "ë¶€ì í•©"
                        }
                        formatted = {
                            "ì‹œê°„": data["timestamp"],
                            "ì™¼ìª½ ì–´ê¹¨": fmt(data["left_shoulder"]),
                            "ì˜¤ë¥¸ìª½ ì–´ê¹¨": fmt(data["right_shoulder"]),
                            "ì™¼ìª½ ë¬´ë¦": fmt(data["left_knee"]),
                            "ì˜¤ë¥¸ìª½ ë¬´ë¦": fmt(data["right_knee"]),
                        }
                        md = f"**ğŸ•’ {formatted['ì‹œê°„']}**\n\n| êµ¬ë¶„ | X | Y | Z | ì‹ ë¢°ë„ | ì í•© |\n|:--:|:--:|:--:|:--:|:--:|:--:|\n"
                        for name, joint in formatted.items():
                            if name != "ì‹œê°„":
                                md += f"| {name} | {joint['X']} | {joint['Y']} | {joint['Z']} | {joint['ì‹ ë¢°ë„']} | {joint['ì í•©']} |\n"
                        landmark_output.markdown(md)
                        last_print_time = current_time

                frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

                # Streamlitì— ì¶œë ¥
                frame_placeholder.image(frame_bgr, channels="BGR", width=320)

                #frame_placeholder.image(frame_bgr, channels="BGR", use_column_width=True)
                time.sleep(0.03)

            cap.release()
