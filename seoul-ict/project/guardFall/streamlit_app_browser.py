import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase
import av
import cv2
import mediapipe as mp
import time
from datetime import datetime
from zoneinfo import ZoneInfo

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë¹„ë™ê¸° ë‚™ìƒ ê°ì§€ ì‹œìŠ¤í…œ",
    layout="wide"
)

# Mediapipe ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# í˜„ì¬ ì‹œê° (KST)
def now_kst():
    return datetime.now(ZoneInfo("Asia/Seoul")).strftime("%Y-%m-%d %H:%M:%S")

# Pose ì¶”ì¶œ í´ë˜ìŠ¤
class PoseVideoProcessor(VideoProcessorBase):
    def __init__(self):
        self.pose = mp_pose.Pose()
        self.landmark_data = {}

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        image = frame.to_ndarray(format="bgr24")
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.pose.process(image_rgb)

        if results.pose_landmarks:
            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

            def extract(p):
                return {"x": p.x, "y": p.y, "z": p.z, "visibility": p.visibility}

            lm = results.pose_landmarks.landmark
            self.landmark_data = {
                "timestamp": now_kst(),
                "left_shoulder": extract(lm[mp_pose.PoseLandmark.LEFT_SHOULDER]),
                "right_shoulder": extract(lm[mp_pose.PoseLandmark.RIGHT_SHOULDER]),
                "left_knee": extract(lm[mp_pose.PoseLandmark.LEFT_KNEE]),
                "right_knee": extract(lm[mp_pose.PoseLandmark.RIGHT_KNEE])
            }

        return av.VideoFrame.from_ndarray(image, format="bgr24")

# UI êµ¬ì„±
st.title("ğŸ¦´ ë¹„ë™ê¸° ì‹¤ì‹œê°„ ê´€ì ˆ ì¶”ì¶œ ì‹œìŠ¤í…œ")

col1, col2 = st.columns(2)

# ğŸ“· ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë°
with col1:
    st.subheader("ğŸ“· ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì˜ìƒ")
    webrtc_ctx = webrtc_streamer(
        key="fall-detection",
        video_processor_factory=PoseVideoProcessor,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

# ğŸ“‹ ê´€ì ˆ ì •ë³´ ì¶œë ¥
with col2:
    st.subheader("ğŸ“‹ ê´€ì ˆ ì •ë³´")
    landmark_box = st.empty()

    if webrtc_ctx.video_processor:
        processor = webrtc_ctx.video_processor
        last_print_time = 0

        while True:
            current_time = time.time()
            data = processor.landmark_data

            if data and current_time - last_print_time >= 1:
                def format_joint(joint):
                    return {
                        "X": f"{joint['x']:.2f}",
                        "Y": f"{joint['y']:.2f}",
                        "Z": f"{joint['z']:.2f}",
                        "ì‹ ë¢°ë„": f"{joint['visibility']:.2f}",
                        "ì í•©": "ì í•©" if joint['visibility'] > 0.7 else "ë¶€ì í•©"
                    }

                formatted = {
                    "ì‹œê°„": data["timestamp"],
                    "ì™¼ìª½ ì–´ê¹¨": format_joint(data["left_shoulder"]),
                    "ì˜¤ë¥¸ìª½ ì–´ê¹¨": format_joint(data["right_shoulder"]),
                    "ì™¼ìª½ ë¬´ë¦": format_joint(data["left_knee"]),
                    "ì˜¤ë¥¸ìª½ ë¬´ë¦": format_joint(data["right_knee"]),
                }

                # í‘œ í˜•íƒœë¡œ ì¶œë ¥
                table_md = f"**ğŸ•’ {formatted['ì‹œê°„']}**\n\n"
                table_md += "| êµ¬ë¶„ | X | Y | Z | ì‹ ë¢°ë„ | ì í•© |\n|:--:|:--:|:--:|:--:|:--:|:--:|\n"
                for name, joint in formatted.items():
                    if name == "ì‹œê°„":
                        continue
                    table_md += f"| {name} | {joint['X']} | {joint['Y']} | {joint['Z']} | {joint['ì‹ ë¢°ë„']} | {joint['ì í•©']} |\n"

                landmark_box.markdown(table_md)
                last_print_time = current_time

            time.sleep(0.03)
