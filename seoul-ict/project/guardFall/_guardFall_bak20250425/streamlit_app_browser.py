import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase
import av
import cv2
import mediapipe as mp
import time
from datetime import datetime
from zoneinfo import ZoneInfo
from collections import defaultdict

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì•± ìµœìƒë‹¨ì— ìœ„ì¹˜)
for key, default in {
    "csv_data": [],
    "csv_ready": False,
    "csv_path": None,
    "downloaded": False
}.items():
    if key not in st.session_state:
        st.session_state[key] = default
        
# ì„¤ì •
st.set_page_config(page_title="ë‚™ìƒ ê°ì§€ ì‹œìŠ¤í…œ", layout="wide")
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# ì‹œê°„ í•¨ìˆ˜
def now_kst():
    return datetime.now(ZoneInfo("Asia/Seoul")).strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]  # ì´ˆ ë‹¨ìœ„ê¹Œì§€ í¬í•¨

# ë‚™ìƒ ì—¬ë¶€ íŒë‹¨
def is_fallen(ls_y, rs_y, lk_y, rk_y, ls_ok, rs_ok, lk_ok, rk_ok):
    if sum([ls_ok, rs_ok, lk_ok, rk_ok]) >= 3:
        count = 0
        if isinstance(ls_y, (int, float)) and ls_y >= 0.55:
            count += 1
        if isinstance(rs_y, (int, float)) and rs_y >= 0.55:
            count += 1
        if isinstance(lk_y, (int, float)) and lk_y >= 0.65:
            count += 1
        if isinstance(rk_y, (int, float)) and rk_y >= 0.65:
            count += 1
        return "FALL" if count >= 3 else "-"
    return "-"

# wide formatìœ¼ë¡œ ë³€í™˜
def convert_to_wide_format(data):
    import pandas as pd
    from collections import defaultdict

    grouped = defaultdict(dict)
    for r in data:
        ts   = r["ì‹œê°„"]
        joint = r["ê´€ì ˆ"]
        grouped[ts][joint] = r

    rows = []
    for ts, joints in grouped.items():
        row = [ts]
        for joint_name in ["ì™¼ìª½ ì–´ê¹¨", "ì˜¤ë¥¸ìª½ ì–´ê¹¨", "ì™¼ìª½ ë¬´ë¦", "ì˜¤ë¥¸ìª½ ë¬´ë¦"]:
            j = joints.get(joint_name, {})
            row.extend([
                j.get("X", ""), j.get("Y", ""), j.get("Z", ""),
                j.get("ì‹ ë¢°ë„", ""), j.get("ì í•©", "")
            ])

        # â”€â”€â”€â”€â”€ ë‚™ìƒ ì—¬ë¶€ ê³„ì‚° â”€â”€â”€â”€â”€
        try:
            ls_y = float(row[2])   # idx 2 = LS_Y
            rs_y = float(row[7])   # idx 7 = RS_Y
            lk_y = float(row[12])  # idx 12 = LK_Y
            rk_y = float(row[17])  # idx 17 = RK_Y

            ls_ok = row[5] == "Y"
            rs_ok = row[10] == "Y"
            lk_ok = row[15] == "Y"
            rk_ok = row[20] == "Y"

            fallen = is_fallen(ls_y, rs_y, lk_y, rk_y, ls_ok, rs_ok, lk_ok, rk_ok)
        except Exception:
            fallen = False

        row.append(fallen)
        rows.append(row)

    columns = [
        "ì‹œê°„",
        "LS_X", "LS_Y", "LS_Z", "LS_ì‹ ë¢°", "LS_ì í•©",
        "RS_X", "RS_Y", "RS_Z", "RS_ì‹ ë¢°", "RS_ì í•©",
        "LK_X", "LK_Y", "LK_Z", "LK_ì‹ ë¢°", "LK_ì í•©",
        "RK_X", "RK_Y", "RK_Z", "RK_ì‹ ë¢°", "RK_ì í•©",
        "ë‚™ìƒì—¬ë¶€"
    ]
    return pd.DataFrame(rows, columns=columns)

# ê´€ì ˆ ì¶”ì¶œ í´ë˜ìŠ¤ (ì›¹ìº ìš©)
class PoseVideoProcessor(VideoProcessorBase):
    def __init__(self):
        self.pose = mp_pose.Pose()
        self.landmark_data = {}

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        image = frame.to_ndarray(format="bgr24")
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.pose.process(image_rgb)

        if results.pose_landmarks:
            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
            def extract(p): return {"x": p.x, "y": p.y, "z": p.z, "visibility": p.visibility}
            lm = results.pose_landmarks.landmark
            self.landmark_data = {
                "timestamp": now_kst(),
                "left_shoulder": extract(lm[mp_pose.PoseLandmark.LEFT_SHOULDER]),
                "right_shoulder": extract(lm[mp_pose.PoseLandmark.RIGHT_SHOULDER]),
                "left_knee": extract(lm[mp_pose.PoseLandmark.LEFT_KNEE]),
                "right_knee": extract(lm[mp_pose.PoseLandmark.RIGHT_KNEE])
            }

        return av.VideoFrame.from_ndarray(image, format="bgr24")

# ì„ íƒ ë©”ë‰´
mode = st.radio("ë¶„ì„ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ğŸ“· ì›¹ìº  ìŠ¤íŠ¸ë¦¬ë°", "ğŸï¸ MP4 ì˜ìƒ ì—…ë¡œë“œ"])

# ì›¹ìº  ëª¨ë“œ
if mode == "ğŸ“· ì›¹ìº  ìŠ¤íŠ¸ë¦¬ë°":
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ì‹¤ì‹œê°„ ì˜ìƒ")
        webrtc_ctx = webrtc_streamer(
            key="webcam",
            video_processor_factory=PoseVideoProcessor,
            media_stream_constraints={"video": True, "audio": False},
            async_processing=True,
        )

    with col2:
        st.subheader("ê´€ì ˆ ì •ë³´")
        landmark_box = st.empty()

        if webrtc_ctx.video_processor:
            processor = webrtc_ctx.video_processor
            last_print_time = 0
            while True:
                current_time = time.time()
                data = processor.landmark_data

                def fmt(j): return {
                    "X": f"{j['x']:.2f}", "Y": f"{j['y']:.2f}",
                    "Z": f"{j['z']:.2f}", "ì‹ ë¢°ë„": f"{j['visibility']:.2f}",
                    "ì í•©": "Y" if j['visibility'] > 0.7 else "N"
                }
                formatted = {
                    "ì‹œê°„": data["timestamp"],
                    "ì™¼ìª½ ì–´ê¹¨": fmt(data["left_shoulder"]),
                    "ì˜¤ë¥¸ìª½ ì–´ê¹¨": fmt(data["right_shoulder"]),
                    "ì™¼ìª½ ë¬´ë¦": fmt(data["left_knee"]),
                    "ì˜¤ë¥¸ìª½ ë¬´ë¦": fmt(data["right_knee"]),
                }
                md = f"**ğŸ•’ {formatted['ì‹œê°„']}**\n\n| êµ¬ë¶„ | X | Y | Z | ì‹ ë¢°ë„ | ì í•© |\n|:--:|:--:|:--:|:--:|:--:|:--:|\n"
                for name, joint in formatted.items():
                    if name != "ì‹œê°„":
                        md += f"| {name} | {joint['X']} | {joint['Y']} | {joint['Z']} | {joint['ì‹ ë¢°ë„']} | {joint['ì í•©']} |\n"
                landmark_box.markdown(md)
                last_print_time = current_time

                time.sleep(0.1)

# ì˜ìƒ ì—…ë¡œë“œ ëª¨ë“œ
else:
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("MP4 ì˜ìƒ ì—…ë¡œë“œ")
        video_file = st.file_uploader("MP4 íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["mp4"])
        if video_file:
            import pandas as pd
            import os
            if "csv_data" not in st.session_state:
                st.session_state.csv_data = []
            if "csv_ready" not in st.session_state:
                st.session_state.csv_ready = False
            if "csv_path" not in st.session_state:
                st.session_state.csv_path = None

            st.session_state.csv_data.clear()

            file_path = f"./mov/{video_file.name}"
            with open(file_path, "wb") as f:
                f.write(video_file.read())

            cap = cv2.VideoCapture(file_path)
            frame_placeholder = st.empty()
            pose = mp_pose.Pose()
            stop_button = st.button("â¹ ì˜ìƒ ì²˜ë¦¬ ì¤‘ì§€")
            last_print_time = 0

    with col2:
        if video_file:
            landmark_output = st.empty()
            while cap.isOpened() and not stop_button:
                ret, frame = cap.read()
                if not ret:
                    st.success("ì˜ìƒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    break

                image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = pose.process(image_rgb)

                if results.pose_landmarks:
                    mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                    def extract(p): return {"x": p.x, "y": p.y, "z": p.z, "visibility": p.visibility}
                    lm = results.pose_landmarks.landmark
                    data = {
                        "timestamp": now_kst(),
                        "left_shoulder": extract(lm[mp_pose.PoseLandmark.LEFT_SHOULDER]),
                        "right_shoulder": extract(lm[mp_pose.PoseLandmark.RIGHT_SHOULDER]),
                        "left_knee": extract(lm[mp_pose.PoseLandmark.LEFT_KNEE]),
                        "right_knee": extract(lm[mp_pose.PoseLandmark.RIGHT_KNEE])
                    }

                    current_time = time.time()
                    def fmt(j): return {
                        "X": f"{j['x']:.2f}", "Y": f"{j['y']:.2f}",
                        "Z": f"{j['z']:.2f}", "ì‹ ë¢°ë„": f"{j['visibility']:.2f}",
                        "ì í•©": "Y" if j['visibility'] > 0.7 else "N"
                    }
                    formatted = {
                        "ì‹œê°„": data["timestamp"],
                        "ì™¼ìª½ ì–´ê¹¨": fmt(data["left_shoulder"]),
                        "ì˜¤ë¥¸ìª½ ì–´ê¹¨": fmt(data["right_shoulder"]),
                        "ì™¼ìª½ ë¬´ë¦": fmt(data["left_knee"]),
                        "ì˜¤ë¥¸ìª½ ë¬´ë¦": fmt(data["right_knee"]),
                    }
                    md = f"**ğŸ•’ {formatted['ì‹œê°„']}**\n\n| êµ¬ë¶„ | X | Y | Z | ì‹ ë¢°ë„ | ì í•© |\n|:--:|:--:|:--:|:--:|:--:|:--:|\n"
                    for name, joint in formatted.items():
                        if name != "ì‹œê°„":
                            md += f"| {name} | {joint['X']} | {joint['Y']} | {joint['Z']} | {joint['ì‹ ë¢°ë„']} | {joint['ì í•©']} |\n"
                            st.session_state.csv_data.append({
                                "ì‹œê°„": formatted["ì‹œê°„"],
                                "ê´€ì ˆ": name,
                                "X": joint["X"],
                                "Y": joint["Y"],
                                "Z": joint["Z"],
                                "ì‹ ë¢°ë„": joint["ì‹ ë¢°ë„"],
                                "ì í•©": joint["ì í•©"]
                            })
                    landmark_output.markdown(md)
                    last_print_time = current_time

                frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                frame_placeholder.image(frame_bgr, channels="BGR", width=320)
                time.sleep(0.03)

            cap.release()
            st.session_state.csv_ready = True

            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì‹¤í–‰ ì¡°ê±´ (ë‹¨ í•œ ë²ˆë§Œ ì‹¤í–‰)
            if st.session_state.csv_ready and st.session_state.csv_data and not st.session_state.downloaded:
                df = convert_to_wide_format(st.session_state.csv_data)
                os.makedirs("./mov/outputs", exist_ok=True)
                #csv_path = f"./outputs/landmarks_{now_kst().replace(':', '-').replace(' ', '_')}.csv"
                base_name = os.path.splitext(video_file.name)[0]  # í™•ì¥ì ì œê±°
                csv_path = f"./mov/outputs/{base_name}.csv"
                df.to_csv(csv_path, index=False, encoding='utf-8-sig')
                st.session_state.csv_path = csv_path
                csv_bytes = df.to_csv(index=False).encode('utf-8-sig')

                if st.download_button(
                    label="ğŸ“¥ ì¢Œí‘œ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv_bytes,
                    file_name=os.path.basename(csv_path),
                    mime="text/csv",
                    key="csv_download_button"
                ):
                    st.session_state.downloaded = True
